{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc0edd381f1f4646a9f4ffdf9032eea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1e42f6b5a7a4d698883d8d0536492d6",
              "IPY_MODEL_beb5a888af0441e4bc145414b25b57c7",
              "IPY_MODEL_a176728330044ec392d80bdf3f933009"
            ],
            "layout": "IPY_MODEL_0b68ead43b1d471982b7eccc54094944"
          }
        },
        "c1e42f6b5a7a4d698883d8d0536492d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19128040d4874c84b51a7b37c9707dbe",
            "placeholder": "​",
            "style": "IPY_MODEL_08fcd5f1331c4974ac660fe670b73a18",
            "value": "100%"
          }
        },
        "beb5a888af0441e4bc145414b25b57c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3028ea1a6bcd43ebb0507888d17b44c3",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_598aaa8bd4944f59b95d611d599bd549",
            "value": 50
          }
        },
        "a176728330044ec392d80bdf3f933009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2641d4d87b9b4dbba22ecde8e0bb2fb4",
            "placeholder": "​",
            "style": "IPY_MODEL_df58abc395e84a57ade25d93720f3699",
            "value": " 50/50 [00:34&lt;00:00,  2.01it/s]"
          }
        },
        "0b68ead43b1d471982b7eccc54094944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19128040d4874c84b51a7b37c9707dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08fcd5f1331c4974ac660fe670b73a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3028ea1a6bcd43ebb0507888d17b44c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "598aaa8bd4944f59b95d611d599bd549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2641d4d87b9b4dbba22ecde8e0bb2fb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df58abc395e84a57ade25d93720f3699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Colab Version of DenseDiffusion**"
      ],
      "metadata": {
        "id": "Hf6B6pZPXGHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn more about it at [XandrChris/DenseDiffusionColab](https://github.com/XandrChris/DenseDiffusionColab)\n",
        "\n",
        "Run it on a T4 GPU\n",
        "\n",
        "To start using this, run the cells with Ctrl+F9 or \"Runtime > Run All\""
      ],
      "metadata": {
        "id": "CAo_NaNkWV6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cloning Repo and Installing Requirements\n",
        "!git clone https://github.com/XandrChris/DenseDiffusionColab\n",
        "%cd DenseDiffusionColab\n",
        "\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q tensorflow-gpu==2.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRFlfSrUWI1R",
        "outputId": "7c930da5-09ab-46a7-d5b0-cf0db0c0b20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DenseDiffusionColab'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 42 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (42/42), 13.40 MiB | 24.37 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "/content/DenseDiffusionColab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DenseDiffusion Colab App\n",
        "HF_TOKEN = \"\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "cVU60lbVWAgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "import requests\n",
        "import random\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from datetime import datetime\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionPipeline\n",
        "from diffusers import DDIMScheduler\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from utils import preprocess_mask, process_sketch, process_prompts, process_example\n",
        "\n",
        "MAX_COLORS = 12\n",
        "\n",
        "\n",
        "#################################################\n",
        "#################################################\n",
        "canvas_html = \"<div id='canvas-root' style='max-width:400px; margin: 0 auto'></div>\"\n",
        "load_js = \"\"\"\n",
        "async () => {\n",
        "const url = \"https://huggingface.co/datasets/radames/gradio-components/raw/main/sketch-canvas.js\"\n",
        "fetch(url)\n",
        "  .then(res => res.text())\n",
        "  .then(text => {\n",
        "    const script = document.createElement('script');\n",
        "    script.type = \"module\"\n",
        "    script.src = URL.createObjectURL(new Blob([text], { type: 'application/javascript' }));\n",
        "    document.head.appendChild(script);\n",
        "  });\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "get_js_colors = \"\"\"\n",
        "async (canvasData) => {\n",
        "  const canvasEl = document.getElementById(\"canvas-root\");\n",
        "  return [canvasEl._data]\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "css = '''\n",
        "#color-bg{display:flex;justify-content: center;align-items: center;}\n",
        ".color-bg-item{width: 100%; height: 32px}\n",
        "#main_button{width:100%}\n",
        "<style>\n",
        "'''\n",
        "\n",
        "\n",
        "#################################################\n",
        "#################################################\n",
        "global sreg, creg, sizereg, COUNT, creg_maps, sreg_maps, pipe, text_cond\n",
        "\n",
        "sreg = 0\n",
        "creg = 0\n",
        "sizereg = 0\n",
        "COUNT = 0\n",
        "reg_sizes = {}\n",
        "creg_maps = {}\n",
        "sreg_maps = {}\n",
        "text_cond = 0\n",
        "device=\"cuda\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "  \"runwayml/stable-diffusion-v1-5\",\n",
        "  cache_dir='./models/diffusers/',\n",
        "  use_auth_token=HF_TOKEN).to(device)\n",
        "clear_output()\n",
        "pipe.safety_checker = lambda images, clip_input: (images, False)\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.scheduler.set_timesteps(50)\n",
        "timesteps = pipe.scheduler.timesteps\n",
        "sp_sz = pipe.unet.sample_size\n",
        "\n",
        "with open('./dataset/valset.pkl', 'rb') as f:\n",
        "    val_prompt = pickle.load(f)\n",
        "val_layout = './dataset/valset_layout/'\n",
        "\n",
        "#################################################\n",
        "#################################################\n",
        "def mod_forward(self, hidden_states, encoder_hidden_states=None, attention_mask=None):\n",
        "\n",
        "    batch_size, sequence_length, _ = hidden_states.shape\n",
        "    attention_mask = self.prepare_attention_mask(attention_mask, sequence_length)\n",
        "\n",
        "    query = self.to_q(hidden_states)\n",
        "    query = self.head_to_batch_dim(query)\n",
        "\n",
        "    global text_cond\n",
        "    context_states = text_cond if encoder_hidden_states is not None else hidden_states\n",
        "    key = self.to_k(context_states)\n",
        "    value = self.to_v(context_states)\n",
        "    key = self.head_to_batch_dim(key)\n",
        "    value = self.head_to_batch_dim(value)\n",
        "\n",
        "    global sreg, creg, COUNT, creg_maps, sreg_maps, reg_sizes\n",
        "    COUNT += 1\n",
        "\n",
        "    if COUNT/32 < 50*0.3:\n",
        "\n",
        "        dtype = query.dtype\n",
        "        if self.upcast_attention:\n",
        "            query = query.float()\n",
        "            key = key.float()\n",
        "\n",
        "        sim = torch.baddbmm(torch.empty(query.shape[0], query.shape[1], key.shape[1],\n",
        "                                        dtype=query.dtype, device=query.device),\n",
        "                            query, key.transpose(-1, -2), beta=0, alpha=self.scale)\n",
        "\n",
        "        treg = torch.pow(timesteps[COUNT//32]/1000, 5)\n",
        "\n",
        "        ## reg at self-attn\n",
        "        if encoder_hidden_states is None:\n",
        "            min_value = sim[int(sim.size(0)/2):].min(-1)[0].unsqueeze(-1)\n",
        "            max_value = sim[int(sim.size(0)/2):].max(-1)[0].unsqueeze(-1)\n",
        "            mask = sreg_maps[sim.size(1)].repeat(self.heads,1,1)\n",
        "            size_reg = reg_sizes[sim.size(1)].repeat(self.heads,1,1)\n",
        "\n",
        "            sim[int(sim.size(0)/2):] += (mask>0)*size_reg*sreg*treg*(max_value-sim[int(sim.size(0)/2):])\n",
        "            sim[int(sim.size(0)/2):] -= ~(mask>0)*size_reg*sreg*treg*(sim[int(sim.size(0)/2):]-min_value)\n",
        "\n",
        "        ## reg at cross-attn\n",
        "        else:\n",
        "            min_value = sim[int(sim.size(0)/2):].min(-1)[0].unsqueeze(-1)\n",
        "            max_value = sim[int(sim.size(0)/2):].max(-1)[0].unsqueeze(-1)\n",
        "            mask = creg_maps[sim.size(1)].repeat(self.heads,1,1)\n",
        "            size_reg = reg_sizes[sim.size(1)].repeat(self.heads,1,1)\n",
        "\n",
        "            sim[int(sim.size(0)/2):] += (mask>0)*size_reg*creg*treg*(max_value-sim[int(sim.size(0)/2):])\n",
        "            sim[int(sim.size(0)/2):] -= ~(mask>0)*size_reg*creg*treg*(sim[int(sim.size(0)/2):]-min_value)\n",
        "\n",
        "        attention_probs = sim.softmax(dim=-1)\n",
        "        attention_probs = attention_probs.to(dtype)\n",
        "\n",
        "    else:\n",
        "        attention_probs = self.get_attention_scores(query, key, attention_mask)\n",
        "\n",
        "    hidden_states = torch.bmm(attention_probs, value)\n",
        "    hidden_states = self.batch_to_head_dim(hidden_states)\n",
        "\n",
        "    # linear proj\n",
        "    hidden_states = self.to_out[0](hidden_states)\n",
        "    # dropout\n",
        "    hidden_states = self.to_out[1](hidden_states)\n",
        "\n",
        "    return hidden_states\n",
        "\n",
        "for _module in pipe.unet.modules():\n",
        "    if _module.__class__.__name__ == \"CrossAttention\":\n",
        "        _module.__class__.__call__ = mod_forward\n",
        "\n",
        "\n",
        "#################################################\n",
        "#################################################\n",
        "def process_generation(binary_matrixes, seed, creg_, sreg_, sizereg_, bsz, master_prompt, *prompts):\n",
        "\n",
        "    global creg, sreg, sizereg\n",
        "    creg, sreg, sizereg = creg_, sreg_, sizereg_\n",
        "\n",
        "    clipped_prompts = prompts[:len(binary_matrixes)]\n",
        "    prompts = [master_prompt] + list(clipped_prompts)\n",
        "    layouts = torch.cat([preprocess_mask(mask_, sp_sz, sp_sz, device) for mask_ in binary_matrixes])\n",
        "\n",
        "    text_input = pipe.tokenizer(prompts, padding=\"max_length\", return_length=True, return_overflowing_tokens=False,\n",
        "                                max_length=pipe.tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
        "    cond_embeddings = pipe.text_encoder(text_input.input_ids.to(device))[0]\n",
        "\n",
        "    uncond_input = pipe.tokenizer([\"\"]*bsz, padding=\"max_length\", max_length=pipe.tokenizer.model_max_length,\n",
        "                                  truncation=True, return_tensors=\"pt\")\n",
        "    uncond_embeddings = pipe.text_encoder(uncond_input.input_ids.to(device))[0]\n",
        "\n",
        "\n",
        "    ###########################\n",
        "    ###### prep for sreg ######\n",
        "    ###########################\n",
        "    global sreg_maps, reg_sizes\n",
        "    sreg_maps = {}\n",
        "    reg_sizes = {}\n",
        "    for r in range(4):\n",
        "        layouts_s = F.interpolate(layouts,(np.power(2,r+3),np.power(2,r+3)),mode='nearest')\n",
        "        layouts_s = (layouts_s.view(layouts_s.size(0),1,-1)*layouts_s.view(layouts_s.size(0),-1,1)).sum(0).unsqueeze(0).repeat(bsz,1,1)\n",
        "        reg_sizes[np.power(2,(r+3)*2)] = 1-sizereg*layouts_s.sum(-1, keepdim=True)/(np.power(2,(r+3)*2))\n",
        "        sreg_maps[np.power(2,(r+3)*2)] = layouts_s\n",
        "\n",
        "\n",
        "    ###########################\n",
        "    ###### prep for creg ######\n",
        "    ###########################\n",
        "    pww_maps = torch.zeros(1,77,64,64).to(device)\n",
        "    for i in range(1,len(prompts)):\n",
        "        wlen = text_input['length'][i] - 2\n",
        "        widx = text_input['input_ids'][i][1:1+wlen]\n",
        "        for j in range(77):\n",
        "            if (text_input['input_ids'][0][j:j+wlen] == widx).sum() == wlen:\n",
        "                pww_maps[:,j:j+wlen,:,:] = layouts[i-1:i]\n",
        "                cond_embeddings[0][j:j+wlen] = cond_embeddings[i][1:1+wlen]\n",
        "                break\n",
        "\n",
        "    global creg_maps\n",
        "    creg_maps = {}\n",
        "    for r in range(4):\n",
        "        layout_c = F.interpolate(pww_maps,(np.power(2,r+3),np.power(2,r+3)),mode='nearest').view(1,77,-1).permute(0,2,1).repeat(bsz,1,1)\n",
        "        creg_maps[np.power(2,(r+3)*2)] = layout_c\n",
        "\n",
        "\n",
        "    ###########################\n",
        "    #### prep for text_emb ####\n",
        "    ###########################\n",
        "    global text_cond\n",
        "    text_cond = torch.cat([uncond_embeddings, cond_embeddings[:1].repeat(bsz,1,1)])\n",
        "\n",
        "    global COUNT\n",
        "    COUNT = 0\n",
        "\n",
        "    if seed == -1:\n",
        "        latents = torch.randn(bsz,4,64,64).to(device)\n",
        "    else:\n",
        "        latents = torch.randn(bsz,4,64,64, generator=torch.Generator().manual_seed(seed)).to(device)\n",
        "\n",
        "    image = pipe(prompts[:1]*bsz, latents=latents).images\n",
        "\n",
        "    return(image)\n",
        "\n",
        "\n",
        "#################################################\n",
        "#################################################\n",
        "### define the interface\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    binary_matrixes = gr.State([])\n",
        "    gr.Markdown('''## DenseDiffusion: Dense Text-to-Image Generation with Attention Modulation''')\n",
        "    gr.Markdown('''\n",
        "    #### 😺 Instruction to generate images 😺\n",
        "    (1) Sketch the layout of the image.\n",
        "    (2) Label each segment with text description.\n",
        "    (3) Adjust the text, which is the integration of segments separated by commas, keeping in mind that the sentence should include every segments. (Default sentence works as well, but using it might be leading to the genration of less pleasing images.)\n",
        "    (4) Check the generated images, and tune the hyperparameters if needed.\n",
        "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - w<sup>c</sup> : The degree of attention modulation at cross-attention layers.\n",
        "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - w<sup>s</sup> : The degree of attention modulation at self-attention layers.\n",
        "    ''')\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Box(elem_id=\"main-image\"):\n",
        "            canvas_data = gr.JSON(value={}, visible=False)\n",
        "            canvas = gr.HTML(canvas_html)\n",
        "            button_run = gr.Button(\"(1) I've finished my sketch ! 😺\", elem_id=\"main_button\", interactive=True)\n",
        "\n",
        "            prompts = []\n",
        "            colors = []\n",
        "            color_row = [None] * MAX_COLORS\n",
        "            with gr.Column(visible=False) as post_sketch:\n",
        "                for n in range(MAX_COLORS):\n",
        "                    if n == 0 :\n",
        "                        with gr.Row(visible=False) as color_row[n]:\n",
        "                            colors.append(gr.Image(shape=(100, 100), label=\"background\", type=\"pil\", image_mode=\"RGB\").style(width=100, height=100))\n",
        "                            prompts.append(gr.Textbox(label=\"Prompt for the background (white region)\", value=\"\"))\n",
        "                    else:\n",
        "                        with gr.Row(visible=False) as color_row[n]:\n",
        "                            colors.append(gr.Image(shape=(100, 100), label=\"segment \"+str(n), type=\"pil\", image_mode=\"RGB\").style(width=100, height=100))\n",
        "                            prompts.append(gr.Textbox(label=\"Prompt for the segment \"+str(n)))\n",
        "\n",
        "                get_genprompt_run = gr.Button(\"(2) I've finished segment labeling ! 😺\", elem_id=\"prompt_button\", interactive=True)\n",
        "\n",
        "            with gr.Column(visible=False) as gen_prompt_vis:\n",
        "                general_prompt = gr.Textbox(value='', label=\"(3) Textual Description for the entire image\", interactive=True)\n",
        "                with gr.Accordion(\"(4) Tune the hyperparameters\", open=False):\n",
        "                    creg_ = gr.Slider(label=\" w\\u1D9C (The degree of attention modulation at cross-attention layers) \", minimum=0, maximum=2., value=1.0, step=0.1)\n",
        "                    sreg_ = gr.Slider(label=\" w \\u02E2 (The degree of attention modulation at self-attention layers) \", minimum=0, maximum=2., value=0.3, step=0.1)\n",
        "                    sizereg_ = gr.Slider(label=\"The degree of mask-area adaptive adjustment\", minimum=0, maximum=1., value=1., step=0.1)\n",
        "                    bsz_ = gr.Slider(label=\"Number of Samples to generate\", minimum=1, maximum=4, value=2, step=1)\n",
        "                    seed_ = gr.Slider(label=\"Seed\", minimum=-1, maximum=999999999, value=-1, step=1)\n",
        "\n",
        "                final_run_btn = gr.Button(\"Generate ! 😺\")\n",
        "\n",
        "                layout_path = gr.Textbox(label=\"layout_path\", visible=False)\n",
        "                all_prompts = gr.Textbox(label=\"all_prompts\", visible=False)\n",
        "\n",
        "        with gr.Column():\n",
        "            out_image = gr.Gallery(label=\"Result\", ).style(columns=2, height='auto')\n",
        "\n",
        "    button_run.click(process_sketch, inputs=[canvas_data], outputs=[post_sketch, binary_matrixes, *color_row, *colors], _js=get_js_colors, queue=False)\n",
        "\n",
        "    get_genprompt_run.click(process_prompts, inputs=[binary_matrixes, *prompts], outputs=[gen_prompt_vis, general_prompt], queue=False)\n",
        "\n",
        "    final_run_btn.click(process_generation, inputs=[binary_matrixes, seed_, creg_, sreg_, sizereg_, bsz_, general_prompt, *prompts], outputs=out_image)\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[[val_layout + '0.png',\n",
        "                   '***'.join([val_prompt[0]['textual_condition']] + val_prompt[0]['segment_descriptions']), 131363121],\n",
        "                  [val_layout + '1.png',\n",
        "                   '***'.join([val_prompt[1]['textual_condition']] + val_prompt[1]['segment_descriptions']), 212669682],\n",
        "                  [val_layout + '5.png',\n",
        "                   '***'.join([val_prompt[5]['textual_condition']] + val_prompt[5]['segment_descriptions']), 96554487]],\n",
        "        inputs=[layout_path, all_prompts, seed_],\n",
        "        outputs=[post_sketch, binary_matrixes, *color_row, *colors, *prompts, gen_prompt_vis, general_prompt, seed_],\n",
        "        fn=process_example,\n",
        "        run_on_click=True,\n",
        "        label='😺 Examples 😺',\n",
        "    )\n",
        "\n",
        "    demo.load(None, None, None, _js=load_js)\n",
        "\n",
        "demo.launch(share=True, debug=True, inline=False, inbrowser=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143,
          "referenced_widgets": [
            "dc0edd381f1f4646a9f4ffdf9032eea4",
            "c1e42f6b5a7a4d698883d8d0536492d6",
            "beb5a888af0441e4bc145414b25b57c7",
            "a176728330044ec392d80bdf3f933009",
            "0b68ead43b1d471982b7eccc54094944",
            "19128040d4874c84b51a7b37c9707dbe",
            "08fcd5f1331c4974ac660fe670b73a18",
            "3028ea1a6bcd43ebb0507888d17b44c3",
            "598aaa8bd4944f59b95d611d599bd549",
            "2641d4d87b9b4dbba22ecde8e0bb2fb4",
            "df58abc395e84a57ade25d93720f3699"
          ]
        },
        "id": "b-LBQ2BdXtNT",
        "outputId": "87f38578-5e70-49c2-95fc-36cb971db3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://a35070dc64d96b90a9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc0edd381f1f4646a9f4ffdf9032eea4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ]
}
