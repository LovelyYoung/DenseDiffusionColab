{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Colab Version of DenseDiffusion**"
      ],
      "metadata": {
        "id": "1WY3aW2BqRkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn more about DenseDiffusion at [naver-ai/DenseDiffusion](https://github.com/naver-ai/DenseDiffusion), more about Colab Demo at [XandrChris/DenseDiffusionColab](https://github.com/XandrChris/DenseDiffusionColab)\n",
        "\n",
        "Run it on a T4 GPU\n",
        "\n",
        "To start using this, run the cells with Ctrl+F9 or \"Runtime > Run All\""
      ],
      "metadata": {
        "id": "NI1EqzT7qVZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q37rLCZiiyl",
        "outputId": "587f8bf5-6315-46fc-9608-985820b96b3b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diffusers==0.20.2\n",
            "transformers==4.28.0\n",
            "gradio\n",
            "accelerate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/XandrChris/DenseDiffusionColab\n",
        "%cd DenseDiffusionColab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4FGlzfai-DY",
        "outputId": "0a62ce51-bc00-4ef1-b23c-0f03f20e5bd5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DenseDiffusionColab' already exists and is not an empty directory.\n",
            "/content/DenseDiffusionColab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import utils"
      ],
      "metadata": {
        "id": "DIGufg2Ai71g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCm8J-4GYsex",
        "outputId": "3f109c00-9092-4233-fdd0-adb47a867b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DenseDiffusionColab' already exists and is not an empty directory.\n",
            "/content/DenseDiffusionColab\n"
          ]
        }
      ],
      "source": [
        "#@title Cloning Repo and Installing Requirements\n",
        "!git clone https://github.com/XandrChris/DenseDiffusionColab\n",
        "%cd DenseDiffusionColab\n",
        "\n",
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YZ4ACdCUjjsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"jax<0.4.0\""
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "va47BCV1htnY",
        "outputId": "e8857fa5-ab45-440f-d575-ef90b6bfdff9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jax<0.4.0\n",
            "  Downloading jax-0.3.25.tar.gz (1.1 MB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from jax<0.4.0) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax<0.4.0) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from jax<0.4.0) (1.15.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from jax<0.4.0) (4.14.0)\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.3.25-py3-none-any.whl size=1308493 sha256=9e485e7b2ee938ddc63ebdae7ac5497066714c7748cd1abac081573644d87871\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/19/ac/cb851bb1975fd762ab12299d9bc796f442f0dde572803d9da2\n",
            "Successfully built jax\n",
            "Installing collected packages: jax\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.6.2\n",
            "    Uninstalling jax-0.6.2:\n",
            "      Successfully uninstalled jax-0.6.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "orbax-checkpoint 0.11.16 requires jax>=0.5.0, but you have jax 0.3.25 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.3.25 which is incompatible.\n",
            "chex 0.1.89 requires jax>=0.4.27, but you have jax 0.3.25 which is incompatible.\n",
            "optax 0.2.5 requires jax>=0.4.27, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.3.25\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jax"
                ]
              },
              "id": "b19486c5630143b3848073fd821513e1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vfG6o39njqaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.20.2 flax jax\n",
        "import diffusers"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4tb_ImCQhYYV",
        "outputId": "5bb9c784-f6b2-4fc3-fe38-b8ff5a2a644e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers==0.20.2\n",
            "  Using cached diffusers-0.20.2-py3-none-any.whl\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.11/dist-packages (0.10.7)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (0.6.2)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.20.2) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.20.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.20.2) (0.33.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.20.2) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.20.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.20.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.20.2) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.20.2) (11.2.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from flax) (1.1.1)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (from flax) (0.2.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (from flax) (0.11.16)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.11/dist-packages (from flax) (0.1.74)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.11/dist-packages (from flax) (13.9.4)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from flax) (4.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from flax) (6.0.2)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax) (0.1.9)\n",
            "Requirement already satisfied: jaxlib<=0.6.2,>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from jax) (0.6.2)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from jax) (0.5.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.11/dist-packages (from jax) (1.15.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.2) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.2) (24.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.2) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.2) (1.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax) (2.19.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers==0.20.2) (3.23.0)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from optax->flax) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.11/dist-packages (from optax->flax) (0.1.89)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax) (1.12.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax) (5.29.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax) (4.12.3)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->flax) (3.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.20.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.20.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.20.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.20.2) (2025.6.15)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.87->optax->flax) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.5.2)\n",
            "Installing collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.34.0\n",
            "    Uninstalling diffusers-0.34.0:\n",
            "      Successfully uninstalled diffusers-0.34.0\n",
            "Successfully installed diffusers-0.20.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "diffusers"
                ]
              },
              "id": "ce48a691865d43149112bb7a5a0ea329"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Enter HF Token\n",
        "HF_TOKEN=\"\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "fakmnlP2mWZv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Main Code\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "import requests\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import tarfile\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from datetime import datetime\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import diffusers\n",
        "from diffusers import DDIMScheduler\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from utils import preprocess_mask, process_sketch, process_prompts, process_example\n",
        "\n",
        "\n",
        "#################################################\n",
        "#################################################\n",
        "canvas_html = \"<div id='canvas-root' style='max-width:400px; margin: 0 auto'></div>\"\n",
        "load_js = \"\"\"\n",
        "async () => {\n",
        "const url = \"https://huggingface.co/datasets/radames/gradio-components/raw/main/sketch-canvas.js\"\n",
        "fetch(url)\n",
        "  .then(res => res.text())\n",
        "  .then(text => {\n",
        "    const script = document.createElement('script');\n",
        "    script.type = \"module\"\n",
        "    script.src = URL.createObjectURL(new Blob([text], { type: 'application/javascript' }));\n",
        "    document.head.appendChild(script);\n",
        "  });\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "get_js_colors = \"\"\"\n",
        "async (canvasData) => {\n",
        "  const canvasEl = document.getElementById(\"canvas-root\");\n",
        "  return [canvasEl._data]\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "css = '''\n",
        "#color-bg{display:flex;justify-content: center;align-items: center;}\n",
        ".color-bg-item{width: 100%; height: 32px}\n",
        "#main_button{width:100%}\n",
        "<style>\n",
        "'''\n",
        "\n",
        "\n",
        "#################################################\n",
        "#################################################\n",
        "global sreg, creg, sizereg, COUNT, creg_maps, sreg_maps, pipe, text_cond\n",
        "\n",
        "sreg = 0\n",
        "creg = 0\n",
        "sizereg = 0\n",
        "COUNT = 0\n",
        "reg_sizes = {}\n",
        "creg_maps = {}\n",
        "sreg_maps = {}\n",
        "text_cond = 0\n",
        "device=\"cuda\"\n",
        "MAX_COLORS = 12\n",
        "\n",
        "\n",
        "pipe = diffusers.StableDiffusionPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        variant=\"fp16\",\n",
        "        cache_dir='./models/diffusers/',\n",
        "        use_auth_token=HF_TOKEN).to(device)\n",
        "\n",
        "clear_output()\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.scheduler.set_timesteps(50)\n",
        "timesteps = pipe.scheduler.timesteps\n",
        "sp_sz = pipe.unet.sample_size\n",
        "\n",
        "with open('./dataset/valset.pkl', 'rb') as f:\n",
        "    val_prompt = pickle.load(f)\n",
        "val_layout = './dataset/valset_layout/'\n",
        "\n",
        "TarFile = tarfile.open('./dataset/valset_layout.tar.gz')\n",
        "TarFile.extractall('Valset_Layout')\n",
        "\n",
        "#################################################\n",
        "#################################################\n",
        "def mod_forward(self, hidden_states, encoder_hidden_states=None, attention_mask=None, temb=None):\n",
        "\n",
        "    residual = hidden_states\n",
        "\n",
        "    if self.spatial_norm is not None:\n",
        "        hidden_states = self.spatial_norm(hidden_states, temb)\n",
        "\n",
        "    input_ndim = hidden_states.ndim\n",
        "\n",
        "    if input_ndim == 4:\n",
        "        batch_size, channel, height, width = hidden_states.shape\n",
        "        hidden_states = hidden_states.view(batch_size, channel, height * width).transpose(1, 2)\n",
        "\n",
        "    batch_size, sequence_length, _ = (hidden_states.shape if encoder_hidden_states is None else encoder_hidden_states.shape)\n",
        "    attention_mask = self.prepare_attention_mask(attention_mask, sequence_length, batch_size)\n",
        "\n",
        "    if self.group_norm is not None:\n",
        "        hidden_states = self.group_norm(hidden_states.transpose(1, 2)).transpose(1, 2)\n",
        "\n",
        "    query = self.to_q(hidden_states)\n",
        "\n",
        "    global sreg, creg, COUNT, creg_maps, sreg_maps, reg_sizes, text_cond\n",
        "\n",
        "    sa_ = True if encoder_hidden_states is None else False\n",
        "    encoder_hidden_states = text_cond if encoder_hidden_states is not None else hidden_states\n",
        "\n",
        "    if self.norm_cross:\n",
        "        encoder_hidden_states = self.norm_encoder_hidden_states(encoder_hidden_states)\n",
        "\n",
        "    key = self.to_k(encoder_hidden_states)\n",
        "    value = self.to_v(encoder_hidden_states)\n",
        "\n",
        "    query = self.head_to_batch_dim(query)\n",
        "    key = self.head_to_batch_dim(key)\n",
        "    value = self.head_to_batch_dim(value)\n",
        "\n",
        "    if COUNT/32 < 50*0.3:\n",
        "\n",
        "        dtype = query.dtype\n",
        "        if self.upcast_attention:\n",
        "            query = query.float()\n",
        "            key = key.float()\n",
        "\n",
        "        sim = torch.baddbmm(torch.empty(query.shape[0], query.shape[1], key.shape[1],\n",
        "                                        dtype=query.dtype, device=query.device),\n",
        "                            query, key.transpose(-1, -2), beta=0, alpha=self.scale)\n",
        "\n",
        "        treg = torch.pow(timesteps[COUNT//32]/1000, 5)\n",
        "\n",
        "        ## reg at self-attn\n",
        "        if sa_:\n",
        "            min_value = sim[int(sim.size(0)/2):].min(-1)[0].unsqueeze(-1)\n",
        "            max_value = sim[int(sim.size(0)/2):].max(-1)[0].unsqueeze(-1)\n",
        "            mask = sreg_maps[sim.size(1)].repeat(self.heads,1,1)\n",
        "            size_reg = reg_sizes[sim.size(1)].repeat(self.heads,1,1)\n",
        "\n",
        "            sim[int(sim.size(0)/2):] += (mask>0)*size_reg*sreg*treg*(max_value-sim[int(sim.size(0)/2):])\n",
        "            sim[int(sim.size(0)/2):] -= ~(mask>0)*size_reg*sreg*treg*(sim[int(sim.size(0)/2):]-min_value)\n",
        "\n",
        "        ## reg at cross-attn\n",
        "        else:\n",
        "            min_value = sim[int(sim.size(0)/2):].min(-1)[0].unsqueeze(-1)\n",
        "            max_value = sim[int(sim.size(0)/2):].max(-1)[0].unsqueeze(-1)\n",
        "            mask = creg_maps[sim.size(1)].repeat(self.heads,1,1)\n",
        "            size_reg = reg_sizes[sim.size(1)].repeat(self.heads,1,1)\n",
        "\n",
        "            sim[int(sim.size(0)/2):] += (mask>0)*size_reg*creg*treg*(max_value-sim[int(sim.size(0)/2):])\n",
        "            sim[int(sim.size(0)/2):] -= ~(mask>0)*size_reg*creg*treg*(sim[int(sim.size(0)/2):]-min_value)\n",
        "\n",
        "        attention_probs = sim.softmax(dim=-1)\n",
        "        attention_probs = attention_probs.to(dtype)\n",
        "\n",
        "    else:\n",
        "        attention_probs = self.get_attention_scores(query, key, attention_mask)\n",
        "\n",
        "    COUNT += 1\n",
        "\n",
        "    hidden_states = torch.bmm(attention_probs, value)\n",
        "    hidden_states = self.batch_to_head_dim(hidden_states)\n",
        "\n",
        "    # linear proj\n",
        "    hidden_states = self.to_out[0](hidden_states)\n",
        "    # dropout\n",
        "    hidden_states = self.to_out[1](hidden_states)\n",
        "\n",
        "    if input_ndim == 4:\n",
        "        hidden_states = hidden_states.transpose(-1, -2).reshape(batch_size, channel, height, width)\n",
        "\n",
        "    if self.residual_connection:\n",
        "        hidden_states = hidden_states + residual\n",
        "\n",
        "    hidden_states = hidden_states / self.rescale_output_factor\n",
        "\n",
        "    return hidden_states\n",
        "\n",
        "for _module in pipe.unet.modules():\n",
        "    if _module.__class__.__name__ == \"Attention\":\n",
        "        _module.__class__.__call__ = mod_forward\n",
        "\n",
        "\n",
        "#################################################\n",
        "#################################################\n",
        "def process_generation(binary_matrixes, seed, creg_, sreg_, sizereg_, bsz, master_prompt, *prompts):\n",
        "\n",
        "    global creg, sreg, sizereg\n",
        "    creg, sreg, sizereg = creg_, sreg_, sizereg_\n",
        "\n",
        "    clipped_prompts = prompts[:len(binary_matrixes)]\n",
        "    prompts = [master_prompt] + list(clipped_prompts)\n",
        "    layouts = torch.cat([preprocess_mask(mask_, sp_sz, sp_sz, device) for mask_ in binary_matrixes])\n",
        "\n",
        "    text_input = pipe.tokenizer(prompts, padding=\"max_length\", return_length=True, return_overflowing_tokens=False,\n",
        "                                max_length=pipe.tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
        "    cond_embeddings = pipe.text_encoder(text_input.input_ids.to(device))[0]\n",
        "\n",
        "    uncond_input = pipe.tokenizer([\"\"]*bsz, padding=\"max_length\", max_length=pipe.tokenizer.model_max_length,\n",
        "                                  truncation=True, return_tensors=\"pt\")\n",
        "    uncond_embeddings = pipe.text_encoder(uncond_input.input_ids.to(device))[0]\n",
        "\n",
        "\n",
        "    ###########################\n",
        "    ###### prep for sreg ######\n",
        "    ###########################\n",
        "    global sreg_maps, reg_sizes\n",
        "    sreg_maps = {}\n",
        "    reg_sizes = {}\n",
        "\n",
        "    for r in range(4):\n",
        "        res = int(sp_sz/np.power(2,r))\n",
        "        layouts_s = F.interpolate(layouts,(res, res),mode='nearest')\n",
        "        layouts_s = (layouts_s.view(layouts_s.size(0),1,-1)*layouts_s.view(layouts_s.size(0),-1,1)).sum(0).unsqueeze(0).repeat(bsz,1,1)\n",
        "        reg_sizes[np.power(res, 2)] = 1-sizereg*layouts_s.sum(-1, keepdim=True)/(np.power(res, 2))\n",
        "        sreg_maps[np.power(res, 2)] = layouts_s\n",
        "\n",
        "\n",
        "    ###########################\n",
        "    ###### prep for creg ######\n",
        "    ###########################\n",
        "    pww_maps = torch.zeros(1,77,sp_sz,sp_sz).to(device)\n",
        "    for i in range(1,len(prompts)):\n",
        "        wlen = text_input['length'][i] - 2\n",
        "        widx = text_input['input_ids'][i][1:1+wlen]\n",
        "        for j in range(77):\n",
        "            try:\n",
        "                if (text_input['input_ids'][0][j:j+wlen] == widx).sum() == wlen:\n",
        "                    pww_maps[:,j:j+wlen,:,:] = layouts[i-1:i]\n",
        "                    cond_embeddings[0][j:j+wlen] = cond_embeddings[i][1:1+wlen]\n",
        "                    break\n",
        "            except:\n",
        "                raise gr.Error(\"Please check whether every segment prompt is included in the full text !\")\n",
        "                return\n",
        "\n",
        "    global creg_maps\n",
        "    creg_maps = {}\n",
        "    for r in range(4):\n",
        "        res = int(sp_sz/np.power(2,r))\n",
        "        layout_c = F.interpolate(pww_maps,(res,res),mode='nearest').view(1,77,-1).permute(0,2,1).repeat(bsz,1,1)\n",
        "        creg_maps[np.power(res, 2)] = layout_c\n",
        "\n",
        "\n",
        "    ###########################\n",
        "    #### prep for text_emb ####\n",
        "    ###########################\n",
        "    global text_cond\n",
        "    text_cond = torch.cat([uncond_embeddings, cond_embeddings[:1].repeat(bsz,1,1)])\n",
        "\n",
        "    global COUNT\n",
        "    COUNT = 0\n",
        "\n",
        "    if seed == -1:\n",
        "        latents = torch.randn(bsz,4,sp_sz,sp_sz).to(device)\n",
        "    else:\n",
        "        latents = torch.randn(bsz,4,sp_sz,sp_sz, generator=torch.Generator().manual_seed(seed)).to(device)\n",
        "\n",
        "    image = pipe(prompts[:1]*bsz, latents=latents).images\n",
        "\n",
        "    return(image)\n",
        "\n",
        "\n",
        "#################################################\n",
        "#################################################\n",
        "### define the interface\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    binary_matrixes = gr.State([])\n",
        "    color_layout = gr.State([])\n",
        "    gr.Markdown('''## DenseDiffusion: Dense Text-to-Image Generation with Attention Modulation''')\n",
        "    gr.Markdown('''\n",
        "    #### ðŸ˜º Instruction to generate images ðŸ˜º <br>\n",
        "    (1) Create the image layout. <br>\n",
        "    (2) Label each segment with a text prompt. <br>\n",
        "    (3) Adjust the full text. The default full text is automatically concatenated from each segment's text. The default one works well, but refineing the full text will further improve the result. <br>\n",
        "    (4) Check the generated images, and tune the hyperparameters if needed. <br>\n",
        "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - w<sup>c</sup> : The degree of attention modulation at cross-attention layers. <br>\n",
        "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - w<sup>s</sup> : The degree of attention modulation at self-attention layers. <br>\n",
        "    ''')\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Box(elem_id=\"main-image\"):\n",
        "            canvas_data = gr.JSON(value={}, visible=False)\n",
        "            canvas = gr.HTML(canvas_html)\n",
        "            button_run = gr.Button(\"(1) I've finished my sketch ! ðŸ˜º\", elem_id=\"main_button\", interactive=True)\n",
        "\n",
        "            prompts = []\n",
        "            colors = []\n",
        "            color_row = [None] * MAX_COLORS\n",
        "            with gr.Column(visible=False) as post_sketch:\n",
        "                for n in range(MAX_COLORS):\n",
        "                    if n == 0 :\n",
        "                        with gr.Row(visible=False) as color_row[n]:\n",
        "                            colors.append(gr.Image(shape=(100, 100), label=\"background\", type=\"pil\", image_mode=\"RGB\", width=100, height=100))\n",
        "                            prompts.append(gr.Textbox(label=\"Prompt for the background (white region)\", value=\"\"))\n",
        "                    else:\n",
        "                        with gr.Row(visible=False) as color_row[n]:\n",
        "                            colors.append(gr.Image(shape=(100, 100), label=\"segment \"+str(n), type=\"pil\", image_mode=\"RGB\", width=100, height=100))\n",
        "                            prompts.append(gr.Textbox(label=\"Prompt for the segment \"+str(n)))\n",
        "\n",
        "                get_genprompt_run = gr.Button(\"(2) I've finished segment labeling ! ðŸ˜º\", elem_id=\"prompt_button\", interactive=True)\n",
        "\n",
        "            with gr.Column(visible=False) as gen_prompt_vis:\n",
        "                general_prompt = gr.Textbox(value='', label=\"(3) Textual Description for the entire image\", interactive=True)\n",
        "                with gr.Accordion(\"(4) Tune the hyperparameters\", open=False):\n",
        "                    creg_ = gr.Slider(label=\" w\\u1D9C (The degree of attention modulation at cross-attention layers) \", minimum=0, maximum=2., value=1.0, step=0.1)\n",
        "                    sreg_ = gr.Slider(label=\" w \\u02E2 (The degree of attention modulation at self-attention layers) \", minimum=0, maximum=2., value=0.3, step=0.1)\n",
        "                    sizereg_ = gr.Slider(label=\"The degree of mask-area adaptive adjustment\", minimum=0, maximum=1., value=1., step=0.1)\n",
        "                    bsz_ = gr.Slider(label=\"Number of Samples to generate\", minimum=1, maximum=4, value=1, step=1)\n",
        "                    seed_ = gr.Slider(label=\"Seed\", minimum=-1, maximum=999999999, value=-1, step=1)\n",
        "\n",
        "                final_run_btn = gr.Button(\"Generate ! ðŸ˜º\")\n",
        "\n",
        "                layout_path = gr.Textbox(label=\"layout_path\", visible=False)\n",
        "                all_prompts = gr.Textbox(label=\"all_prompts\", visible=False)\n",
        "\n",
        "        with gr.Column():\n",
        "            out_image = gr.Gallery(label=\"Result\", columns=2, height='auto')\n",
        "\n",
        "    button_run.click(process_sketch, inputs=[canvas_data], outputs=[post_sketch, binary_matrixes, *color_row, *colors], _js=get_js_colors, queue=False)\n",
        "\n",
        "    get_genprompt_run.click(process_prompts, inputs=[binary_matrixes, *prompts], outputs=[gen_prompt_vis, general_prompt], queue=False)\n",
        "\n",
        "    final_run_btn.click(process_generation, inputs=[binary_matrixes, seed_, creg_, sreg_, sizereg_, bsz_, general_prompt, *prompts], outputs=out_image)\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[['./Valset_Layout/valset_layout/0.png',\n",
        "                   '***'.join([val_prompt[0]['textual_condition']] + val_prompt[0]['segment_descriptions']), 381940206],\n",
        "                  ['./Valset_Layout/valset_layout/1.png',\n",
        "                   '***'.join([val_prompt[1]['textual_condition']] + val_prompt[1]['segment_descriptions']), 307504592],\n",
        "                  ['./Valset_Layout/valset_layout/5.png',\n",
        "                   '***'.join([val_prompt[5]['textual_condition']] + val_prompt[5]['segment_descriptions']), 114972190]],\n",
        "        inputs=[layout_path, all_prompts, seed_],\n",
        "        outputs=[post_sketch, binary_matrixes, *color_row, *colors, *prompts, gen_prompt_vis, general_prompt, seed_],\n",
        "        fn=process_example,\n",
        "        run_on_click=True,\n",
        "        label='ðŸ˜º Examples ðŸ˜º',\n",
        "    )\n",
        "\n",
        "    demo.load(None, None, None, _js=load_js)\n",
        "\n",
        "demo.launch(share=True,inline=False,debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "BmQrfRsEcvI5",
        "outputId": "4b23b624-e011-42e6-a734-7620df9d33d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'cached_download' from 'huggingface_hub' (/usr/local/lib/python3.11/dist-packages/huggingface_hub/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-3951830043.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdiffusers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffusers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDDIMScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCLIPTextModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIPTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.20.2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m from .utils import (\n\u001b[1;32m      5\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/configuration_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m from .utils import (\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mDIFFUSERS_CACHE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeprecation_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdoc_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreplace_example_docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdynamic_modules_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_class_from_dynamic_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m from .hub_utils import (\n\u001b[1;32m     39\u001b[0m     \u001b[0mHF_HUB_OFFLINE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/utils/dynamic_modules_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_hub_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpackaging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'cached_download' from 'huggingface_hub' (/usr/local/lib/python3.11/dist-packages/huggingface_hub/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}